{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LAB WORKS**  \n",
    "1. Use **German** and **Indian** Languages for text analysis.\n",
    "2. Tokenize and vectorize the extracted tokens from the both Languages.\n",
    "\n",
    "**VECTORISATION**  \n",
    "It is a method of creating a frequency occurance matirx.\n",
    "1. create a list of unique words in the entire corpus.\n",
    "2. create a [mxn] matirx where **m** is the number of sentences in the corpus and **n** is the number of unique words in the corpus.\n",
    "3. for each sentence, iterate through the list of unique words and do a simple count of the word frequency and update the [**m,n**] the position to the frequencey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING NECESSARY PACKAGES\n",
    "\n",
    "import nltk\n",
    "\n",
    "# packages to extract text from a pdf\n",
    "import pdfplumber\n",
    "\n",
    "# package to tokenize text\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# package to convert words to it's original form\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# package to vectorize tokens based on frequency of appearance\n",
    "from sklearn.feature_extraction.text  import CountVectorizer\n",
    "\n",
    "# package to vectorize tokens based on frequency of appearance and remove bias \n",
    "# seen because the corpus does not contain varied text\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "\n",
    "# package to convert vectors to dataframes\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO EXTRACT TEXT FROM PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # initializing a variable 'text' as en empty string\n",
    "    text = \"\"\n",
    "\n",
    "    # opeinging the pdf with the path of the pdf passed through the function parameters\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "\n",
    "        # iterating through the pages of the pdf\n",
    "        for page in pdf.pages:\n",
    "\n",
    "            # extracting the text from each page and adding it to the variable 'text'\n",
    "            text += page.extract_text()\n",
    "\n",
    "    # return the entrire corpus\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GERMAN LANGUAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE GERMAN CORPUS\n",
    "\n",
    "# local file path to get the pdf\n",
    "pdf_path = r\"C:\\Users\\HP\\OneDrive\\Documents\\Post_Grad\\Semester_3\\NLP\\Data\\germanText.pdf\"\n",
    "\n",
    "# extracting the text in the pdf as string\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# converting the string to a list of sentences\n",
    "german_text=text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Das', 'ist', 'ein', 'Beispieltext', 'auf', 'Deutsch', '.'], ['Ist', 'liebe', 'es', ',', 'im', 'Park', 'spazieren', 'zu', 'gehen', '.'], ['Die', 'Sonne', 'scheint', 'heute', 'besonders', 'hell', '.'], ['Mein', 'Lieblingsbuch', 'ist', 'ein', 'Klassiker', 'der', 'Weltliteratur', '.'], ['Ich', 'freue', 'mich', 'auf', 'das', 'Wochenende', '.'], ['Gestern', 'habe', 'ich', 'eine', 'interessante', 'Dokumentation', 'gesehen', '.'], ['Kannst', 'du', 'mir', 'bitte', 'das', 'Salz', 'reichen', '?'], ['Wir', 'planen', 'eine', 'Reise', 'in', 'die', 'Berge', '.'], ['Das', 'Konzert', 'gestern', 'Abend', 'war', 'großartig', '.'], ['Der', 'Kuchen', ',', 'den', 'meine', 'Oma', 'backt', ',', 'ist', 'köstlich', '.'], ['In', 'Deutschland', 'gibt', 'es', 'viele', 'historische', 'Schlösser', '.']]\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZING THE GERMAN TEXT\n",
    "german_text_tokens=[]\n",
    "\n",
    "for i in range(len(german_text)):\n",
    "    german_text_tokens.append(word_tokenize(german_text[i]))\n",
    "\n",
    "print(german_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['das', 'ist', 'ein', 'beispieltext', 'auf', 'deutsch'], ['ist', 'liebe', 'es', 'im', 'park', 'spazieren', 'zu', 'gehen'], ['die', 'sonne', 'scheint', 'heute', 'besonders', 'hell'], ['mein', 'lieblingsbuch', 'ist', 'ein', 'klassiker', 'der', 'weltliteratur'], ['ich', 'freue', 'mich', 'auf', 'das', 'wochenende'], ['gestern', 'habe', 'ich', 'eine', 'interessante', 'dokumentation', 'gesehen'], ['kannst', 'du', 'mir', 'bitte', 'das', 'salz', 'reichen'], ['wir', 'planen', 'eine', 'reise', 'in', 'die', 'berge'], ['das', 'konzert', 'gestern', 'abend', 'war', 'großartig'], ['der', 'kuchen', 'den', 'meine', 'oma', 'backt', 'ist', 'köstlich'], ['in', 'deutschland', 'gibt', 'es', 'viele', 'historische', 'schlösser']]\n"
     ]
    }
   ],
   "source": [
    "german_text_tokens1=[]\n",
    "\n",
    "for a in german_text_tokens:\n",
    "    m=[token.lower() for token in a if token.isalpha()]\n",
    "    german_text_tokens1.append(m)\n",
    "\n",
    "print(german_text_tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING PUNCUATIONS\n",
    "for i in range(len(german_text_tokens)):\n",
    "    if ',' in german_text_tokens[i]:\n",
    "        german_text_tokens[i].remove(',')\n",
    "\n",
    "    if '.' in german_text_tokens[i]:\n",
    "        german_text_tokens[i].remove('.')\n",
    "    \n",
    "    if '?' in german_text_tokens[i]:\n",
    "        german_text_tokens[i].remove('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the german stemming object\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "\n",
    "german_stemed_text=[]\n",
    "\n",
    "# stemming all words in the corpus \n",
    "for i in range(len(german_text_tokens1)):\n",
    "    m=\"\"\n",
    "    for j in range(len(german_text_tokens1[i])):\n",
    "        m=m+\" \"+stemmer.stem(german_text_tokens1[i][j])\n",
    "    german_stemed_text.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' das ist ein beispieltext auf deutsch', ' ist lieb es im park spazi zu geh', ' die sonn scheint heut besond hell', ' mein lieblingsbuch ist ein klassik der weltliteratur', ' ich freu mich auf das wochen', ' gest hab ich ein interessant dokumentation geseh', ' kann du mir bitt das salz reich', ' wir plan ein reis in die berg', ' das konzert gest abend war grossart', ' der kuch den mein oma backt ist kostlich', ' in deutschland gibt es viel histor schloss']\n"
     ]
    }
   ],
   "source": [
    "print(german_stemed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an CountVectorize object\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# applying CountVectorisation on the german_text data\n",
    "count_vectorized_germanText=count_vectorizer.fit_transform(german_stemed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying all unique tokens recognised\n",
    "german_text=count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abend</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auf</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beispieltext</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>besond</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>das</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>der</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deutsch</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deutschland</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dokumentation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   1   2   3   4   5   6   7   8   9   10\n",
       "abend           0   0   0   0   0   0   0   0   1   0   0\n",
       "auf             1   0   0   0   1   0   0   0   0   0   0\n",
       "backt           0   0   0   0   0   0   0   0   0   1   0\n",
       "beispieltext    1   0   0   0   0   0   0   0   0   0   0\n",
       "berg            0   0   0   0   0   0   0   1   0   0   0\n",
       "besond          0   0   1   0   0   0   0   0   0   0   0\n",
       "bitt            0   0   0   0   0   0   1   0   0   0   0\n",
       "das             1   0   0   0   1   0   1   0   1   0   0\n",
       "den             0   0   0   0   0   0   0   0   0   1   0\n",
       "der             0   0   0   1   0   0   0   0   0   1   0\n",
       "deutsch         1   0   0   0   0   0   0   0   0   0   0\n",
       "deutschland     0   0   0   0   0   0   0   0   0   0   1\n",
       "die             0   0   1   0   0   0   0   1   0   0   0\n",
       "dokumentation   0   0   0   0   0   1   0   0   0   0   0\n",
       "du              0   0   0   0   0   0   1   0   0   0   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing a count vectorisation on the tokens and corpus\n",
    "df=DataFrame(count_vectorized_germanText.toarray(),columns=german_text).T\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abend</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auf</th>\n",
       "      <td>0.422937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380348</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beispieltext</th>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>besond</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417733</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>das</th>\n",
       "      <td>0.332400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.303095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380348</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>der</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.36907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325108</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deutsch</th>\n",
       "      <td>0.494800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deutschland</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>die</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357063</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dokumentation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>du</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0    1         2        3         4         5         6   \\\n",
       "abend          0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "auf            0.422937  0.0  0.000000  0.00000  0.385650  0.000000  0.000000   \n",
       "backt          0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "beispieltext   0.494800  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "berg           0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "besond         0.000000  0.0  0.417733  0.00000  0.000000  0.000000  0.000000   \n",
       "bitt           0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.393710   \n",
       "das            0.332400  0.0  0.000000  0.00000  0.303095  0.000000  0.264489   \n",
       "den            0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "der            0.000000  0.0  0.000000  0.36907  0.000000  0.000000  0.000000   \n",
       "deutsch        0.494800  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "deutschland    0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "die            0.000000  0.0  0.357063  0.00000  0.000000  0.000000  0.000000   \n",
       "dokumentation  0.000000  0.0  0.000000  0.00000  0.000000  0.411257  0.000000   \n",
       "du             0.000000  0.0  0.000000  0.00000  0.000000  0.000000  0.393710   \n",
       "\n",
       "                     7         8         9         10  \n",
       "abend          0.000000  0.439293  0.000000  0.000000  \n",
       "auf            0.000000  0.000000  0.000000  0.000000  \n",
       "backt          0.000000  0.000000  0.380348  0.000000  \n",
       "beispieltext   0.000000  0.000000  0.000000  0.000000  \n",
       "berg           0.411257  0.000000  0.000000  0.000000  \n",
       "besond         0.000000  0.000000  0.000000  0.000000  \n",
       "bitt           0.000000  0.000000  0.000000  0.000000  \n",
       "das            0.000000  0.295112  0.000000  0.000000  \n",
       "den            0.000000  0.000000  0.380348  0.000000  \n",
       "der            0.000000  0.000000  0.325108  0.000000  \n",
       "deutsch        0.000000  0.000000  0.000000  0.000000  \n",
       "deutschland    0.000000  0.000000  0.000000  0.393407  \n",
       "die            0.351527  0.000000  0.000000  0.000000  \n",
       "dokumentation  0.000000  0.000000  0.000000  0.000000  \n",
       "du             0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a idf vectorizer object\n",
    "idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# applying Ifd Vectorisation on the german_text data\n",
    "idf_vectorized_germanText=idf_vectorizer.fit_transform(german_stemed_text)\n",
    "\n",
    "# displaying the idf verctorized dataframe\n",
    "df2=DataFrame(idf_vectorized_germanText.toarray(),columns=idf_vectorizer.get_feature_names_out()).T\n",
    "\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INDIAN LANGUAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE INDIAN CORPUS\n",
    "\n",
    "# local file path to get the pdf\n",
    "pdf_path = r\"C:\\Users\\HP\\OneDrive\\Documents\\Post_Grad\\Semester_3\\NLP\\Data\\indianText.pdf\"\n",
    "\n",
    "# extracting the text in the pdf as string\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# converting the string to a list of sentences\n",
    "indian_text=text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING INDIAN CORPUS\n",
    "indian_text_tokens=[]\n",
    "\n",
    "for i in range(len(indian_text)):\n",
    "    indian_text_tokens.append(word_tokenize(indian_text[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations\n",
    "for i in range(len(indian_text_tokens)):\n",
    "    if ',' in indian_text_tokens[i]:\n",
    "        indian_text_tokens[i].remove('|')\n",
    "\n",
    "    if '.' in indian_text_tokens[i]:\n",
    "        indian_text_tokens[i].remove('.')\n",
    "    \n",
    "    if '?' in indian_text_tokens[i]:\n",
    "        indian_text_tokens[i].remove('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270c7e96b1e44903bb3f4f49c5232be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:42:29 INFO: Downloading default packages for language: hi (Hindi) ...\n",
      "2023-10-09 15:42:31 INFO: File exists: C:\\Users\\HP\\stanza_resources\\hi\\default.zip\n",
      "2023-10-09 15:42:34 INFO: Finished downloading models and saved to C:\\Users\\HP\\stanza_resources.\n",
      "2023-10-09 15:42:34 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6db647917548048d136d87d89c0e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:42:36 INFO: Loading these models for language: hi (Hindi):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | hdtb          |\n",
      "| pos       | hdtb_charlm   |\n",
      "| lemma     | hdtb_nocharlm |\n",
      "| depparse  | hdtb_charlm   |\n",
      "=============================\n",
      "\n",
      "2023-10-09 15:42:36 INFO: Using device: cpu\n",
      "2023-10-09 15:42:36 INFO: Loading: tokenize\n",
      "2023-10-09 15:42:36 INFO: Loading: pos\n",
      "2023-10-09 15:42:36 INFO: Loading: lemma\n",
      "2023-10-09 15:42:36 INFO: Loading: depparse\n",
      "2023-10-09 15:42:37 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download the Hindi model\n",
    "stanza.download(\"hi\")\n",
    "\n",
    "# hindi package for processing hindi\n",
    "nlp = stanza.Pipeline(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_stemed_text=[]\n",
    "\n",
    "# stemming the hindi language\n",
    "for i in range(len(indian_text_tokens)):\n",
    "    m=\"\"\n",
    "    for j in range(len(indian_text_tokens[i])):\n",
    "        doc = nlp(indian_text_tokens[i][j])\n",
    "        m=m+doc.text \n",
    "    indian_stemed_text.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['अच' 'अपन' 'आजम' 'आत' 'आपक' 'इस' 'उसन' 'ओरढलरह' 'करखत' 'गकए' 'गकरत' 'गग'\n",
      " 'गतह' 'गबल' 'गहए' 'डरनह' 'तआजआरह' 'तक' 'फलख' 'बहज' 'मक' 'रजपग' 'लकरन'\n",
      " 'लभ' 'वक' 'सएकप' 'सपन' 'समबड' 'सह' 'हमअपन']\n"
     ]
    }
   ],
   "source": [
    "# applying CountVectorisation on the german_text data\n",
    "count_vectorized_indianText=count_vectorizer.fit_transform(indian_stemed_text)\n",
    "\n",
    "# displaying all unique tokens recognised\n",
    "print(count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>अच</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>अपन</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आजम</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आत</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आपक</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>इस</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>उसन</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ओरढलरह</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>करखत</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गकए</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गकरत</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गग</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गतह</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गबल</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गहए</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2  3  4  5  6  7  8  9\n",
       "अच      0  1  0  0  0  0  0  0  0  0\n",
       "अपन     0  0  0  0  0  0  0  0  1  0\n",
       "आजम     0  1  0  0  0  0  0  0  0  0\n",
       "आत      0  0  0  0  0  1  0  0  0  0\n",
       "आपक     0  0  0  0  0  1  0  1  0  0\n",
       "इस      0  0  0  0  0  0  1  0  0  0\n",
       "उसन     0  0  0  0  0  0  0  0  1  0\n",
       "ओरढलरह  0  0  0  0  0  0  0  0  0  1\n",
       "करखत    0  0  0  0  1  0  0  0  0  0\n",
       "गकए     0  0  0  0  0  0  0  0  1  0\n",
       "गकरत    1  0  0  0  0  0  0  0  0  0\n",
       "गग      1  0  0  0  0  0  0  0  0  0\n",
       "गतह     0  0  0  0  0  0  0  1  0  0\n",
       "गबल     0  0  0  0  0  1  0  0  0  0\n",
       "गहए     0  0  0  0  0  0  1  0  0  0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing a count vectorisation on the tokens and corpus\n",
    "df=DataFrame(count_vectorized_indianText.toarray(),columns=count_vectorizer.get_feature_names_out()).T\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>अच</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>अपन</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आजम</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आत</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आपक</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>इस</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>उसन</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ओरढलरह</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>करखत</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गकए</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गकरत</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गग</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गतह</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गबल</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>गहए</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1    2    3         4         5         6         7  \\\n",
       "अच      0.00000  0.57735  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "अपन     0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "आजम     0.00000  0.57735  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "आत      0.00000  0.00000  0.0  0.0  0.000000  0.460158  0.000000  0.000000   \n",
       "आपक     0.00000  0.00000  0.0  0.0  0.000000  0.391176  0.000000  0.647689   \n",
       "इस      0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.377964  0.000000   \n",
       "उसन     0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "ओरढलरह  0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "करखत    0.00000  0.00000  0.0  0.0  0.707107  0.000000  0.000000  0.000000   \n",
       "गकए     0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "गकरत    0.57735  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "गग      0.57735  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "गतह     0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.000000  0.761905   \n",
       "गबल     0.00000  0.00000  0.0  0.0  0.000000  0.460158  0.000000  0.000000   \n",
       "गहए     0.00000  0.00000  0.0  0.0  0.000000  0.000000  0.377964  0.000000   \n",
       "\n",
       "          8        9  \n",
       "अच      0.0  0.00000  \n",
       "अपन     0.5  0.00000  \n",
       "आजम     0.0  0.00000  \n",
       "आत      0.0  0.00000  \n",
       "आपक     0.0  0.00000  \n",
       "इस      0.0  0.00000  \n",
       "उसन     0.5  0.00000  \n",
       "ओरढलरह  0.0  0.57735  \n",
       "करखत    0.0  0.00000  \n",
       "गकए     0.5  0.00000  \n",
       "गकरत    0.0  0.00000  \n",
       "गग      0.0  0.00000  \n",
       "गतह     0.0  0.00000  \n",
       "गबल     0.0  0.00000  \n",
       "गहए     0.0  0.00000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying Ifd Vectorisation on the german_text data\n",
    "idf_vectorized_indianText=idf_vectorizer.fit_transform(indian_stemed_text)\n",
    "\n",
    "# displaying the idf verctorized dataframe\n",
    "df=DataFrame(idf_vectorized_indianText.toarray(),columns=idf_vectorizer.get_feature_names_out()).T\n",
    "\n",
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
